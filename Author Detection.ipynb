{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "The competition dataset contains text from works of fiction written by spooky authors of the public domain: Edgar Allan Poe, HP Lovecraft and Mary Shelley. The data was prepared by chunking larger texts into sentences using CoreNLP's MaxEnt sentence tokenizer, so you may notice the odd non-sentence here and there. Your objective is to accurately identify the author of the sentences in the test set.\n",
    "\n",
    "Borrowed from https://www.kaggle.com/c/spooky-author-identification\n",
    "\n",
    "##### File descriptions\n",
    "`train.csv` - the training set\n",
    "\n",
    "`test.csv` - the test set\n",
    "\n",
    "`sample_submission.csv` - a sample submission file in the correct format\n",
    "\n",
    "##### Data fields\n",
    "`id` - a unique identifier for each sentence\n",
    "\n",
    "`text` - some text written by one of the authors\n",
    "\n",
    "`author` - the author of the sentence (EAP: Edgar Allan Poe, HPL: HP Lovecraft; MWS: Mary Wollstonecraft Shelley)\n",
    "\n",
    "A reminder about playground competitions: On Kaggle, the spirit of playground competitions is to have fun and learn together. Your score on the leaderboard doesn't earn you points, but you can still make it a rewarding competition for everyone by sharing your code in Kernels and contributing to Discussions (there are prizes for both!). In short, please don't look up the answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries #\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from time import time\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all data #\n",
    "\n",
    "authored_contents = pandas.read_csv(\"./author detection datasets/train.csv\")\n",
    "\n",
    "unauthored_contents = pandas.read_csv(\"./author detection datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unauthored_contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here is to scan through the test documents and identify the potential author of each document.\n",
    "\n",
    "`text` represents the documents and is our feature.\n",
    "\n",
    "`author` is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>id07303</td>\n",
       "      <td>I escaped from them to the room where lay the ...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text author\n",
       "count     19579                                              19579  19579\n",
       "unique    19579                                              19579      3\n",
       "top     id07303  I escaped from them to the room where lay the ...    EAP\n",
       "freq          1                                                  1   7900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of authored contents: ', 19579)\n",
      "('Total number of authored contents by EAP: ', 7900)\n",
      "('Total number of authored contents by MWS: ', 6044)\n",
      "('Total number of authored contents by HPL: ', 5635)\n"
     ]
    }
   ],
   "source": [
    "training_records = len(authored_contents)\n",
    "\n",
    "author_eap, author_mws, author_hpl = authored_contents.author.value_counts()\n",
    "\n",
    "print(\"Total number of authored contents: \", training_records)\n",
    "print(\"Total number of authored contents by EAP: \", author_eap)\n",
    "print(\"Total number of authored contents by MWS: \", author_mws)\n",
    "print(\"Total number of authored contents by HPL: \", author_hpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we shall study the text length in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab text length of each contents\n",
    "\n",
    "authored_contents['text_length'] = authored_contents['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "   text_length  \n",
       "0          231  \n",
       "1           71  \n",
       "2          200  \n",
       "3          206  \n",
       "4          174  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAFNCAYAAADcnIQFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0ab4cad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(14,5))\n",
    "sns.countplot(authored_contents['author'],)\n",
    "pyplot.xlabel('Author')\n",
    "pyplot.title('Target variable distribution')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, grouping all the documents by each author to better understand the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "EAP    7900\n",
       "HPL    5635\n",
       "MWS    6044\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.groupby('author').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we shall study the text length in the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine the same in test data\n",
    "\n",
    "testing_records = len(unauthored_contents)\n",
    "\n",
    "unauthored_contents['text_length'] = unauthored_contents['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  text_length\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...          110\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...          330\n",
       "2  id00134  And when they had broken down the frail door t...          189\n",
       "3  id27757  While I was thinking how I should possibly man...          223\n",
       "4  id04081  I am not sure to what limit his knowledge may ...           53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unauthored_contents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, learning algorithms expect input to be numeric, which requires that non-numeric features (called categorical variables) be converted. \n",
    "\n",
    "As with the non-numeric features, we need to convert the non-numeric target label, `author` to numerical values for the learning algorithm to work. Since there are only three possible categories for this label (\"EAP\", \"HPL\" and \"MWS\"), we can avoid using one-hot encoding and simply encode these two categories as 0, 1 and 2 respectively.\n",
    "\n",
    "In code cell below, you will need to implement the following:\n",
    "\n",
    "- Convert the target label 'income_raw' to numerical entries. Set records with \"EAP\" to 0, records with \"HPL\" to 1 and records with \"MWS\" to 2 and storing it in `numerical_author` column.\n",
    "- Downcase, stem and remove punctations from the `text` ad storing it in `scrubbed_text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# binarize author in the training dataset\n",
    "\n",
    "authored_contents['numerical_author'] = authored_contents.author.map({ 'EAP': 0, 'HPL': 1, 'MWS': 2 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_length</th>\n",
       "      <th>numerical_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "   text_length  numerical_author  \n",
       "0          231                 0  \n",
       "1           71                 1  \n",
       "2          200                 0  \n",
       "3          206                 2  \n",
       "4          174                 1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authored_contents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def scrub_text(data_frame):\n",
    "    sentences = []\n",
    "    for i in data_frame.values:\n",
    "        sentence = unicode(i[1], 'utf-8')\n",
    "\n",
    "        # remove all punctuations\n",
    "        sentence = sentence.translate(string.punctuation)\n",
    "\n",
    "        # break sentence into words\n",
    "        array_of_words = word_tokenize(sentence)\n",
    "\n",
    "        # removes all English stopwords\n",
    "        array_of_words = [word for word in array_of_words if word.lower() not in all_stopwords]\n",
    "\n",
    "        # singularise words in the array_of_words\n",
    "        array_of_words = [ps.stem(word) for word in array_of_words]\n",
    "        cleaned_sentence = ' '.join(array_of_words)\n",
    "\n",
    "        sentences.append(cleaned_sentence)\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the #scrub_text over the text in the training and testing datasets.\n",
    "\n",
    "training_cleaned_texts = scrub_text(authored_contents)\n",
    "testing_cleaned_texts = scrub_text(unauthored_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authored_contents['scrubbed_text'] = training_cleaned_texts\n",
    "\n",
    "unauthored_contents['scrubbed_text'] = testing_cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define labels and features set\n",
    "\n",
    "X = authored_contents['scrubbed_text']\n",
    "Y = authored_contents['numerical_author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavitakanojiya/anaconda2/envs/udacity/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,\n",
    "                                                    Y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 15663 features.\n",
      "Testing set has 3916 features.\n",
      "Training set has 15663 labels.\n",
      "Testing set has 3916 labels.\n",
      "\n",
      "Printing labels set...\n",
      "0    6300\n",
      "2    4830\n",
      "1    4533\n",
      "Name: numerical_author, dtype: int64\n",
      "0    1600\n",
      "2    1214\n",
      "1    1102\n",
      "Name: numerical_author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show the results of the split\n",
    "\n",
    "# Features\n",
    "print(\"Training set has \" + str(X_train.shape[0]) + \" features.\")\n",
    "print(\"Testing set has \" + str(X_test.shape[0]) + \" features.\")\n",
    "\n",
    "# Labels\n",
    "print(\"Training set has \" + str(Y_train.shape[0]) + \" labels.\")\n",
    "print(\"Testing set has \" + str(Y_test.shape[0]) + \" labels.\")\n",
    "\n",
    "print(\"\\nPrinting labels set...\")\n",
    "print(Y_train.value_counts())\n",
    "\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Another cross validation:\n",
    "\n",
    "We will now cross-validate our training set using `sklearn.model_selection.StratifiedShuffleSplit` approach\n",
    "\n",
    "This as mentioned in the training videos, this will divide our training set into N folds.\n",
    "We will iterate over each fold acting as testing data at a single point of time and rest of them will act as training sets.\n",
    "\n",
    "We will tweak certain parameters to learn the dataset pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X,\n",
    "                                                        Y,\n",
    "                                                        stratify = Y,\n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 15663 features.\n",
      "Testing set has 3916 features.\n",
      "\n",
      "Training set has 15663 labels.\n",
      "Testing set has 3916 labels.\n",
      "\n",
      "Printing labels set...\n",
      "0    6300\n",
      "2    4830\n",
      "1    4533\n",
      "Name: numerical_author, dtype: int64\n",
      "0    1600\n",
      "2    1214\n",
      "1    1102\n",
      "Name: numerical_author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show the results of the split\n",
    "\n",
    "# Features\n",
    "print(\"Training set has \" + str(X2_train.shape[0]) + \" features.\")\n",
    "print(\"Testing set has \" + str(X2_test.shape[0]) + \" features.\")\n",
    "\n",
    "# Labels\n",
    "print(\"\\nTraining set has \" + str(Y2_train.shape[0]) + \" labels.\")\n",
    "print(\"Testing set has \" + str(Y2_test.shape[0]) + \" labels.\")\n",
    "\n",
    "print(\"\\nPrinting labels set...\")\n",
    "print(Y_train.value_counts())\n",
    "\n",
    "print(Y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features out of the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now grab the words in a document and tokenize them and build vocabulary out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "training_vectorizer = vectorizer.transform(X2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some of the supervised learning models that will be used to evaluate the performance of the model on this problem and the dataset.\n",
    "\n",
    "- Multinomial Naive Bayes\n",
    "- Logistic Regression\n",
    "- XGBoost from the ensemble methods\n",
    "- SVM\n",
    "- Stochastic Gradient Descent Classifier (SGDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include libraries to evaluate performances on the attached dataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: 0.823660287491\n",
      "Training time: 0.0937268733978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7)\n",
    "\n",
    "model = MultinomialNB()\n",
    "start = time()\n",
    "results = cross_val_score(model, training_vectorizer, Y2_train, cv=kfold)\n",
    "end = time()\n",
    "\n",
    "print(\"Mean value: {}\").format(results.mean())\n",
    "print(\"Training time: {}\").format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: 0.805338637495\n",
      "Training time: 2.65445709229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7)\n",
    "\n",
    "model = LogisticRegression()\n",
    "start = time()\n",
    "results = cross_val_score(model, training_vectorizer, Y2_train, cv=kfold)\n",
    "end = time()\n",
    "\n",
    "print(\"Mean value: {}\").format(results.mean())\n",
    "print(\"Training time: {}\").format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: 0.403498032945\n",
      "Training time: 299.708959103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7)\n",
    "\n",
    "model = SVC()\n",
    "start = time()\n",
    "results = cross_val_score(model, training_vectorizer, Y2_train, cv=kfold)\n",
    "end = time()\n",
    "\n",
    "print(\"Mean value: {}\").format(results.mean())\n",
    "print(\"Training time: {}\").format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: 0.794548604234\n",
      "Training time: 0.322958230972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 7)\n",
    "\n",
    "model = SGDClassifier()\n",
    "start = time()\n",
    "results = cross_val_score(model, training_vectorizer, Y2_train, cv=kfold)\n",
    "end = time()\n",
    "\n",
    "print(\"Mean value: {}\").format(results.mean())\n",
    "print(\"Training time: {}\").format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: 0.612143091753\n",
      "Training time: 52.5109481812\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "start = time()\n",
    "results = cross_val_score(model, training_vectorizer, Y2_train, cv=kfold)\n",
    "end = time()\n",
    "\n",
    "print(\"Mean value: {}\").format(results.mean())\n",
    "print(\"Training time: {}\").format(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "         Algorithm            Mean accuracy    Training time            O/P\n",
    "    Multinomial Naive Bayes      0.823            0.093        .82 accuracy with the least amount of training time\n",
    "     Logistic Regression         0.805            2.654        .80 accuracy with some amount of training time\n",
    "            SGDC                 0.794            0.322        .79 accuracy with the least of training time\n",
    "          XGBoost                0.612            52.510       .61 accuracy with unacceptable training time\n",
    "            SVM                  0.403            299.708      least accuracy with highest amount of training time\n",
    "\n",
    "Keeping accuracy with training time, I will move ahead with Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14423\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run vectorizer for X2_test\n",
    "\n",
    "testing_vectorizer = vectorizer.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15663x14423 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 197739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3916x14423 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 49899 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the above transformation, training_vectorizer is our feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune the chosen model. Use grid search (GridSearchCV) with at least one important parameter tuned with at least 3 different values. We will need to use the entire training set for this.\n",
    "\n",
    "In the code cell below, we shall implement the following:\n",
    "\n",
    "- Import sklearn.grid_search.GridSearchCV and sklearn.metrics.make_scorer.\n",
    "- Initialize the classifier you've chosen and store it in `model`.\n",
    "- Create a dictionary of parameters you wish to tune for the chosen model.\n",
    "  Example: parameters = {'parameter' : [list of values]}.\n",
    "- Use make_scorer to create an fbeta_score scoring object (with $\\beta = 0.5$).\n",
    "- Perform grid search on the classifier clf using the 'scorer', and store it in grid_obj.\n",
    "- Fit the grid search object to the training data (`training_vectorizer, Y2_train`), and store it in grid_fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "parameters = { 'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0] }\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "grid_obj = GridSearchCV(model, parameters)\n",
    "\n",
    "grid_fit = grid_obj.fit(training_vectorizer, Y2_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "grid_fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(training_vectorizer, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_prediction = mnb.predict(training_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_prediction = mnb.predict(testing_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83324821246169556"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate score for predicted data against testing data\n",
    "from sklearn import metrics\n",
    "\n",
    "# compare predicted resultset with the test set\n",
    "metrics.accuracy_score(Y2_test, Y_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90934048394305045"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate score for predicted data against training data\n",
    "\n",
    "metrics.accuracy_score(Y2_train, Y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1295,  111,  174],\n",
       "       [  95,  951,   81],\n",
       "       [ 119,   73, 1017]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "\n",
    "metrics.confusion_matrix(Y2_test, Y_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99786719e-01,   2.13280088e-04,   4.89994895e-10],\n",
       "       [  8.66947595e-01,   9.95241185e-02,   3.35282869e-02],\n",
       "       [  8.49678290e-01,   1.45988380e-01,   4.33333032e-03],\n",
       "       [  9.99898759e-01,   5.47849938e-05,   4.64555177e-05],\n",
       "       [  5.00125060e-01,   7.70779393e-03,   4.92167146e-01],\n",
       "       [  6.01738666e-12,   9.54460415e-12,   1.00000000e+00],\n",
       "       [  1.10104174e-07,   9.91861523e-01,   8.13836718e-03],\n",
       "       [  5.96328213e-09,   1.26892029e-13,   9.99999994e-01],\n",
       "       [  1.81717396e-05,   9.99885477e-01,   9.63511503e-05],\n",
       "       [  3.35899059e-01,   6.00869334e-01,   6.32316074e-02]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "y_pred_prob = mnb.predict_proba(testing_vectorizer)\n",
    "y_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        EAP       0.92      0.89      0.91      6320\n",
      "        HPL       0.92      0.92      0.92      4508\n",
      "        MWS       0.88      0.92      0.90      4835\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y2_train, Y_train_prediction, target_names=['EAP', 'HPL', 'MWS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial naive bayes AUC: 0.535750677017\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y2_train, Y_train_prediction, pos_label = 1)\n",
    "\n",
    "print(\"Multinomial naive bayes AUC: {0}\").format(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the prediction over `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorise the unauthored_contents\n",
    "\n",
    "unpredicted_texts = unauthored_contents['text']\n",
    "\n",
    "unpredicted_texts_vectorizer = vectorizer.transform(unpredicted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8392x14423 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 99981 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpredicted_texts_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpredicted_texts_prediction = mnb.predict(unpredicted_texts_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.20145424e-01,   1.65946539e-05,   7.79837982e-01],\n",
       "       [  1.00000000e+00,   5.41858656e-16,   2.72654739e-15],\n",
       "       [  9.99999954e-01,   1.06708018e-11,   4.59154695e-08],\n",
       "       [  9.99999686e-01,   7.66512661e-11,   3.14064718e-07],\n",
       "       [  9.99994603e-01,   3.73458037e-06,   1.66197799e-06],\n",
       "       [  9.99991508e-01,   8.33126697e-11,   8.49152919e-06],\n",
       "       [  9.99995839e-01,   2.71821471e-06,   1.44304027e-06],\n",
       "       [  9.99987890e-01,   2.16332280e-08,   1.20879117e-05],\n",
       "       [  1.00000000e+00,   6.23110653e-18,   3.44319780e-10],\n",
       "       [  9.59449853e-01,   1.92011226e-04,   4.03581360e-02]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "predicted_prob = mnb.predict_proba(unpredicted_texts_vectorizer)\n",
    "predicted_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpredicted_texts_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8392"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unauthored_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_authors = pandas.DataFrame(unpredicted_texts_prediction, columns=['num_author'])\n",
    "\n",
    "predicted_unauthored_contents = pandas.concat([unauthored_contents, numerical_authors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_unauthored_contents['author'] = predicted_unauthored_contents.num_author.map({ 0: 'EAP', 1: 'HPL', 2: 'MWS' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "EAP    7534\n",
       "HPL     282\n",
       "MWS     576\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_unauthored_contents.groupby('author').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>scrubbed_text</th>\n",
       "      <th>num_author</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>110</td>\n",
       "      <td>still , urg leav ireland inquietud impati , fa...</td>\n",
       "      <td>2</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>330</td>\n",
       "      <td>fire want fan , could readili fan newspap , go...</td>\n",
       "      <td>0</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>189</td>\n",
       "      <td>broken frail door found : two cleanli pick hum...</td>\n",
       "      <td>0</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>223</td>\n",
       "      <td>think possibl manag without , one actual tumbl...</td>\n",
       "      <td>0</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>53</td>\n",
       "      <td>sure limit knowledg may extend .</td>\n",
       "      <td>0</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  text_length  \\\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...          110   \n",
       "1  id24541  If a fire wanted fanning, it could readily be ...          330   \n",
       "2  id00134  And when they had broken down the frail door t...          189   \n",
       "3  id27757  While I was thinking how I should possibly man...          223   \n",
       "4  id04081  I am not sure to what limit his knowledge may ...           53   \n",
       "\n",
       "                                       scrubbed_text  num_author author  \n",
       "0  still , urg leav ireland inquietud impati , fa...           2    MWS  \n",
       "1  fire want fan , could readili fan newspap , go...           0    EAP  \n",
       "2  broken frail door found : two cleanli pick hum...           0    EAP  \n",
       "3  think possibl manag without , one actual tumbl...           0    EAP  \n",
       "4                   sure limit knowledg may extend .           0    EAP  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_unauthored_contents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write modified train.csv and test.csv to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authored_contents.to_csv('./author detection datasets/authored_contents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_unauthored_contents.to_csv('./author detection datasets/predicted_unauthored_contents.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
